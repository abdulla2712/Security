{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGfQM6lrLkKm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.collections as mat\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "features = pd.read_csv('./T2_data/malware_data.csv', header=None)\n",
        "#print(features)\n",
        "labels = pd.read_csv('./T2_data/malware_label.csv', header=None)\n",
        "labels = labels.drop(0, axis=1)\n",
        "labels = labels.rename(columns = {1:'label'})\n",
        "#print(labels)\n",
        "mal1_index = 17000\n",
        "mal2_index = 21000\n",
        "mal3_index = 12000\n",
        "indices=[mal1_index,mal2_index,mal3_index]\n",
        "mal_range = 50\n",
        "mal_test_range = 30\n",
        "\n",
        "def set_data(index1,index2):\n",
        "    train_data = np.vstack([ features[mal1_index:mal1_index+mal_range][[index1,index2]].values, features[mal2_index:mal2_index+mal_range][[index1,index2]].values, features[mal3_index:mal3_index+mal_range][[index1,index2]].values ])\n",
        "    train_data = pd.DataFrame(train_data)    \n",
        "    full_data=np.array(train_data)\n",
        "    train_labels = np.vstack([ labels[mal1_index:mal1_index+mal_range].values, labels[mal2_index:mal2_index+mal_range].values, labels[mal3_index:mal3_index+mal_range].values ])\n",
        "    train_labels = pd.DataFrame(train_labels)\n",
        "   \n",
        "    train_data['labels'] = train_labels\n",
        "    train_data = train_data.rename(columns={0:'x', 1:'y'})\n",
        "   \n",
        "    test_data = np.vstack([ features[mal1_index + mal_range:mal1_index+mal_range+mal_test_range][[index1,index2]].values, features[mal2_index+mal_range:mal2_index+mal_range+mal_test_range][[index1,index2]].values, features[mal3_index+mal_range:mal3_index+mal_range+mal_test_range][[index1,index2]].values ])\n",
        "    test_data = pd.DataFrame(test_data)\n",
        "    full_data=np.concatenate((full_data,np.array(test_data)))\n",
        "\n",
        "    test_labels = np.vstack([ labels[mal1_index+mal_range:mal1_index+mal_range+mal_test_range].values, labels[mal2_index+mal_range:mal2_index+mal_range+mal_test_range].values, labels[mal3_index+mal_range:mal3_index+mal_range+mal_test_range].values ])\n",
        "    test_labels = pd.DataFrame(test_labels)\n",
        "    test_data['labels'] = test_labels\n",
        "    test_data = test_data.rename(columns={0:'x', 1:'y'})\n",
        "\n",
        "    return train_data,test_data,full_data\n",
        "\n",
        "def classifier():\n",
        "    \n",
        "    # DO NOT MODIFY THIS CELL - this cell is splitting the data to provide a suitable subset of data to work with for this task.\n",
        "    # If you change this cell your output will differ from that expected and could impact your mark.    \n",
        "\n",
        "    train_data,test_data,full_data=set_data(0,1)\n",
        "    \n",
        "    train_data2=np.array(train_data)\n",
        "    test_data2=np.array(test_data)\n",
        "\n",
        "   ################# Centroids #####################\n",
        "   #assign centroids\n",
        "    centroids=[]\n",
        "    for i in range(3):\n",
        "        centroids.append(get_centroid(indices[i], mal_range))\n",
        "    centroids=np.array(centroids)\n",
        "    #print centroids\n",
        "    print(\"Centroid Point for Dataset 1 is: (\"+str(centroids[0,0])+\" , \"+str(centroids[0,1])+\")\")\n",
        "    print(\"Centroid Point for Dataset 2 is: (\"+str(centroids[1,0])+\" , \"+str(centroids[1,1])+\")\")\n",
        "    print(\"Centroid Point for Dataset 3 is: (\"+str(centroids[2,0])+\" , \"+str(centroids[2,1])+\")\")\n",
        "    ###################################################\n",
        "    plt.scatter(train_data['x'], train_data['y'],color='k')\n",
        "    \n",
        "    ###################### assign groups ############################\n",
        "    group1,group2,group3,score=find_groups(centroids,test_data2,train_data2)\n",
        "    #define the success score\n",
        "    print(\"Score of Success of Classifier is: (\"+str(score)+\" )\")\n",
        "    #define the accuracy\n",
        "    score=score/len(test_data2)\n",
        "    print(\"Accuracy of Classifier is : (\"+str(score)+\" )\") #(Total No. of correct prediction/Total No. of Prediction )\n",
        "    ##############################################################\n",
        "   \n",
        "    centroids=np.array([np.mean(group1,axis=0), np.mean(group2,axis=0), np.mean(group3,axis=0)]) #update centroid\n",
        "\n",
        "    ######### standarize the full data ##################\n",
        "    full_data=standarize(full_data)\n",
        "    print(\"Scaled Data:\")\n",
        "    print(\"------------\")\n",
        "    print(full_data)\n",
        "    #################################################\n",
        "\n",
        "    ############ Label Encode ###################\n",
        "    frames = [train_data, test_data]  \n",
        "    full_data_with_label = pd.concat(frames)\n",
        "    labelEncode(full_data_with_label)\n",
        "    print(\"Encoded Labels Data:\")\n",
        "    print(\"--------------------\")\n",
        "    print(full_data_with_label)\n",
        "    #############################################\n",
        "\n",
        "    ###### Split the data ############\n",
        "    X_train, X_test, y_train, y_test=split_data(full_data_with_label,full_data_with_label['labels'])\n",
        "    print(\"Splitted Data:\")\n",
        "    print(\"--------------\")\n",
        "    print (\"X_train: \")\n",
        "    print(X_train)\n",
        "    print (\"y_train:\")\n",
        "    print(y_train)\n",
        "    print(\"X_test: \")\n",
        "    print(X_test)\n",
        "    print (\"y_test: \")\n",
        "    print(y_test)\n",
        "    ###################\n",
        "\n",
        "    ###### MPL Classifiier ############\n",
        "    predicted_values=mpl_classifier(X_train,y_train,X_test)\n",
        "    print(\"MPL Classifier Data:\")\n",
        "    print(\"--------------------\")\n",
        "    print(\"MLP Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test,predicted_values))\n",
        "    print(\"MLP Classification Report:\")\n",
        "    print(classification_report(y_test,predicted_values))\n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted_values))\n",
        "    ##################################\n",
        "\n",
        "    ###### Random Forest Classifiier ############\n",
        "    rf_prediction=random_forest(X_train,y_train,X_test)\n",
        "    print(\"Random Forest Classifier:\")\n",
        "    print(\"-------------------------\")\n",
        "    print(\"RF Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test,rf_prediction))\n",
        "    print(\"RF Classification Report:\")\n",
        "    print(classification_report(y_test,rf_prediction))\n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, rf_prediction))\n",
        "    ##################################\n",
        "\n",
        "    ####Plot The Centroids Generated from Train Data##\n",
        "    plt.scatter(centroids[0,0],centroids[0,1],marker='x',color='r')\n",
        "    plt.scatter(centroids[1,0],centroids[1,1],marker='x',color='g')\n",
        "    plt.scatter(centroids[2,0],centroids[2,1],marker='x',color='b')   \n",
        "    plt.xlabel('Feature X')\n",
        "    plt.ylabel('Feature Y')   \n",
        "    ##################\n",
        "\n",
        "    ####Plott Groups of Test Data##\n",
        "    plt.scatter(group1[:,0], group1[:,1], color='r')\n",
        "    plt.scatter(group2[:,0], group2[:,1], color='g')\n",
        "    plt.scatter(group3[:,0], group3[:,1], color='b')\n",
        "    ##################\n",
        "    plt.show()\n",
        "    ############ Best Accuracy ############\n",
        "    print(\"Best Accuracy for Classifier:\")\n",
        "    print(\"-----------------------------\")\n",
        "    get_best_accuracy()\n",
        "    #######################################\n",
        "\n",
        "def get_centroid(mal_index,mal_range):\n",
        "    points=features[mal_index:mal_index+mal_range][[0,1]].values\n",
        "    x =  [p[0] for p in points]\n",
        "    y =  [p[1] for p in points]\n",
        "    centroid = [sum(x) / len(points), sum(y) / len(points)]\n",
        "    return centroid\n",
        "\n",
        "def find_groups(centroids,all_data,train_data):\n",
        "    group1=[]\n",
        "    group2=[]\n",
        "    group3=[]\n",
        "    groups=[group1,group2,group3]\n",
        "    score=0\n",
        "    for i in range(all_data.shape[0]):\n",
        "        distance1=np.sqrt(np.abs(all_data[i , 0] - centroids[0,0]) ** 2 + np.abs(all_data[i,1] - centroids[0,1]) ** 2)\n",
        "        distance2=np.sqrt(np.abs(all_data[i , 0] - centroids[1,0]) ** 2 + np.abs(all_data[i,1] - centroids[1,1]) ** 2)\n",
        "        distance3=np.sqrt(np.abs(all_data[i , 0] - centroids[2,0]) ** 2 + np.abs(all_data[i,1] - centroids[2,1]) ** 2)\n",
        "        distances=[distance1, distance2, distance3]\n",
        "        index=np.argmin(distances)\n",
        "        label_test=all_data[i , 2]\n",
        "        label_centroid=train_data[index * mal_range,2]\n",
        "        if(label_test == label_centroid):\n",
        "            score+=1\n",
        "        groups[index].append([all_data[i,0] , all_data[i,1]])\n",
        "    group1=np.array(group1)\n",
        "    group2=np.array(group2)\n",
        "    group3=np.array(group3)\n",
        "    return group1,group2,group3,score\n",
        "\n",
        "def standarize(full_data):\n",
        "    # the scaler object (model)\n",
        "    scaler = StandardScaler()\n",
        "    # fit and transform the data\n",
        "    scaled_data = scaler.fit_transform(full_data)\n",
        "    return scaled_data\n",
        "\n",
        "def labelEncode(df):\n",
        "    #create instance of label encoder\n",
        "    lab = LabelEncoder()    \n",
        "    #perform label encoding on 'team' column\n",
        "    df['labels'] = lab.fit_transform(df['labels'])\n",
        "\n",
        "def split_data(full_data,labels):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(full_data,labels,random_state=104, test_size=0.25, shuffle=True)    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def mpl_classifier(x_train,y_train,x_test):\n",
        "    m1 = MLPClassifier(hidden_layer_sizes=(12, 13, 14), activation='relu', solver='adam', max_iter=2500)\n",
        "    m1.fit(x_train, y_train.values.ravel())\n",
        "    predicted_values = m1.predict(x_test)\n",
        "    return predicted_values\n",
        "\n",
        "def random_forest(x_train,y_train,x_test):\n",
        "    #Create a Gaussian Classifier\n",
        "    clf=RandomForestClassifier(n_estimators=100)\n",
        "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "    clf.fit(x_train,y_train)\n",
        "    y_pred=clf.predict(x_test)\n",
        "    return y_pred\n",
        "\n",
        "def get_best_accuracy():\n",
        "    accuracy=0\n",
        "    for i in range(255):\n",
        "        if(accuracy < 0.80):\n",
        "            j=i+1\n",
        "            train_data,test_data,full_data=set_data(i,j)\n",
        "            frames = [train_data, test_data]  \n",
        "            full_data_with_label = pd.concat(frames)\n",
        "            labelEncode(full_data_with_label)\n",
        "            X_train, X_test, y_train, y_test=split_data(full_data_with_label,full_data_with_label['labels'])\n",
        "            ###### MPL Classifiier ############\n",
        "            predicted_values=mpl_classifier(X_train,y_train,X_test)\n",
        "            accuracy=metrics.accuracy_score(y_test, predicted_values)\n",
        "            ##################################\n",
        "        else:    \n",
        "            print(\"Best Accuracy For ML is : \",accuracy)\n",
        "            print(\"Used Feature Columns: \"+str(i+1)+\" and \"+str(j+1))\n",
        "            return\n",
        "    print(\"Can't achieve 80% \")    \n",
        "\n",
        "def main():\n",
        "    classifier() \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}